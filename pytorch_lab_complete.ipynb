{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce503e7c",
   "metadata": {},
   "source": [
    "# Lab: Introduction to Neural Networks in PyTorch\n",
    "\n",
    "**Duration:** 3 Hours\n",
    "**Topic:** Tensors, Linear Regression, and Non-Linear Neural Networks (MLPs)\n",
    "\n",
    "## 1. Introduction\n",
    "In this laboratory, you will explore PyTorch tensors, build a linear regression model, and finally construct a Multi-Layer Perceptron (MLP) to solve a non-linear classification problem.\n",
    "\n",
    "**Learning Objectives:**\n",
    "1. Manipulate PyTorch tensors.\n",
    "2. Build custom `nn.Module` classes.\n",
    "3. Understand why non-linearity (ReLU) is essential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cfd60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "print(f'PyTorch version: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca0a9d5",
   "metadata": {},
   "source": [
    "## Part 1: Tensors (The Building Blocks)\n",
    "Tensors are multi-dimensional arrays similar to NumPy arrays but can run on GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b365a7f2",
   "metadata": {},
   "source": [
    "### Exercise 1: Creating Tensors\n",
    "**Task:**\n",
    "1. Create a random tensor with shape `(5, 3)` using `torch.rand`.\n",
    "2. Create a tensor of all ones with shape `(2, 2)`.\n",
    "3. Print their shapes and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708ccc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1274a81",
   "metadata": {},
   "source": [
    "### Exercise 2: Matrix Multiplication & Shapes\n",
    "Matrix multiplication is strict about shapes. Inner dimensions must match: `(A, B) @ (B, C)` works.\n",
    "**Task:** Fix the error in the code below using a transpose `.T` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8f3a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_A = torch.tensor([[1, 2], [3, 4], [5, 6]]) # Shape (3, 2)\n",
    "tensor_B = torch.tensor([[7, 10], [8, 11], [9, 12]]) # Shape (3, 2)\n",
    "\n",
    "# TODO: Fix this line so it runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f768ed52",
   "metadata": {},
   "source": [
    "## Part 2: Linear Regression Data\n",
    "We will create synthetic data for a linear regression problem: $y = weight * X + bias$.\n",
    "\n",
    "1.  **Define Parameters:** Set `weight = 0.7` and `bias = 0.3`.\n",
    "2.  **Generate Data:**\n",
    "    * Create a tensor `X` with values from `0` to `1` with a step of `0.02`.\n",
    "    * Create a tensor `y` using the linear regression formula: $y = \\text{weight} \\times X + \\text{bias}$.\n",
    "3.  **Split Data:**\n",
    "    * Calculate the split index for an **80/20** split (80% training, 20% testing).\n",
    "    * Create `X_train`, `y_train`, `X_test`, and `y_test` based on this split.\n",
    "4.  **Verify:** Print the number of samples in the training and testing sets to confirm the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf922d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "300be5cc",
   "metadata": {},
   "source": [
    "### Exercise 3: Visualization\n",
    "**Task:** Run the helper function below to visualize the linear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91c13a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train, train_labels=y_train, \n",
    "                     test_data=X_test, test_labels=y_test, predictions=None):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(train_data, train_labels, c='b', s=4, label='Training data')\n",
    "    plt.scatter(test_data, test_labels, c='g', s=4, label='Testing data')\n",
    "    if predictions is not None:\n",
    "        plt.scatter(test_data, predictions, c='r', s=4, label='Predictions')\n",
    "    plt.legend(prop={'size': 14})\n",
    "    plt.show()\n",
    "\n",
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f020564",
   "metadata": {},
   "source": [
    "## Part 3: Building a Linear Model\n",
    "**Exercise 4:** Define a subclass of `nn.Module` called `LinearRegressionModel`. Use `nn.Linear` in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        # TODO: Define a linear layer: in_features=1, out_features=1\n",
    "\n",
    "\n",
    "    def forward(....) -> torch.Tensor:\n",
    "        # TODO: Implement forward pass\n",
    "        return \n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_0 = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb724656",
   "metadata": {},
   "source": [
    "## Part 4: Training\n",
    "**Exercise 5:** Setup Loss and Optimizer. Use `nn.L1Loss` (MAE) and `torch.optim.SGD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define Loss and Optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9382a92e",
   "metadata": {},
   "source": [
    "**Exercise 6:** Complete the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b5a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model_0.train()\n",
    "    # 1. Forward pass\n",
    "    # 2. Calculate loss\n",
    "    # 3. Zero gradients\n",
    "    # 4. Backpropagation\n",
    "    # 5. Step optimizer\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch} | Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59715627",
   "metadata": {},
   "source": [
    "**Exercise 7:** Prediction. Make predictions on `X_test` using `torch.inference_mode()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c1e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO make preds\n",
    "\n",
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9a6633",
   "metadata": {},
   "source": [
    "## Part 6: Non-Linear Data & Neural Networks (MLP)\n",
    "Linear models cannot separate concentric circles. We need a neural network with **non-linear activation functions** (like ReLU) to bend the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate non-linear data\n",
    "n_samples = 1000\n",
    "X_circles, y_circles = make_circles(n_samples, noise=0.03, random_state=42)\n",
    "\n",
    "# Convert to tensors\n",
    "\n",
    "# Split data\n",
    "\n",
    "# Visualize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d901a10",
   "metadata": {},
   "source": [
    "### Exercise 8: Building a Non-Linear Model (MLP)\n",
    "**Task:** Create a class `CircleModel` that subclasses `nn.Module`.\n",
    "1. In `__init__`, define: \n",
    "   - `layer_1`: Linear (input 2 -> hidden 10)\n",
    "   - `relu`: ReLU activation\n",
    "   - `layer_2`: Linear (hidden 10 -> output 1)\n",
    "2. In `forward`, connect them: `x -> layer_1 -> relu -> layer_2 -> output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06972205",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        # TODO: Define layers here\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "\n",
    "model_1 = CircleModel()\n",
    "print(model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c233c8bf",
   "metadata": {},
   "source": [
    "### Exercise 9: Training the Classifier\n",
    "**Task:** Train the model for 1000 epochs.\n",
    "1. Loss Function: Use `nn.BCEWithLogitsLoss()` (Binary Cross Entropy for classification).\n",
    "2. Optimizer: `SGD` with `lr=0.1`.\n",
    "3. Loop: Forward pass -> Calculate Loss -> Zero Grad -> Backward -> Step.\n",
    "*Hint: The model outputs 'logits'. To get accuracy, convert logits to labels.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9501a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model_1.train()\n",
    "    \n",
    "    # 1. Forward pass\n",
    "    \n",
    "    # 2. Calculate loss\n",
    "    \n",
    "    # 3. Optimization step\n",
    "\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch} | Loss: {loss.item():.5f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
